<!DOCTYPE html>
<html lang="pt-BR">
  <head>
    <meta charset="UTF-8" />
    <title>KPI – Indicador de Estabilidade (% de testes estáveis)</title>
    <link rel="stylesheet" href="styles.css" />
  </head>

  <body>
    <div id="sidebar"></div>
    <script>
      fetch("sidebar.html")
        .then((r) => r.text())
        .then((t) => (document.getElementById("sidebar").innerHTML = t));
    </script>

    <div id="content">
      <h1>
        KPI – Indicador de Estabilidade<br />
        (% de Testes Estáveis)
      </h1>

      <div class="section-block">
        <h2>1. Objetivo do KPI</h2>
        <p>
          Este KPI mede o <strong>percentual de testes estáveis</strong> dentro
          da suíte, considerando a repetibilidade dos resultados entre
          execuções.
        </p>

        <p>Um teste estável é aquele que:</p>
        <ul>
          <li>Apresenta resultados consistentes</li>
          <li>Não oscila entre passed/failed sem alteração real no produto</li>
          <li>
            Não depende de fatores externos instáveis (ambiente, dados
            aleatórios, etc.)
          </li>
        </ul>

        <p>
          É um indicador essencial para medir a confiabilidade dos testes,
          qualidade do processo e maturidade da automação.
        </p>

        <h2>2. Regras de Negócio</h2>

        <h3>2.1 RN01 – O que define um teste instável?</h3>
        <p>
          Um teste é considerado <strong>instável</strong> se, ao longo do ciclo
          ou do mês:
        </p>
        <ul>
          <li>Apresenta intermitência (flaky test)</li>
          <li>Falha sem alteração do código</li>
          <li>Falha por motivo externo (ambiente, rede, dado)</li>
          <li>Altera o resultado repetidamente (passa/falha/retest)</li>
        </ul>

        <h3>2.2 RN02 – Definição de teste estável</h3>
        <p>Um teste é <strong>estável</strong> se:</p>

        <ul>
          <li>Atinge o mesmo resultado repetidamente</li>
          <li>Falha apenas por defeitos reais</li>
          <li>Não apresenta histórico de flakiness</li>
        </ul>

        <h3>2.3 RN03 – Janela de observação</h3>
        <p>Pode ser configurado por:</p>
        <ul>
          <li>Release</li>
          <li>Mês</li>
          <li>Sprint</li>
        </ul>

        <p>O padrão recomendado é: <strong>janela da release</strong>.</p>

        <h3>2.4 RN04 – Fórmula do KPI</h3>
        <p>
          <strong>
            % Estáveis = (Total de testes estáveis ÷ total de testes executados)
            × 100
          </strong>
        </p>

        <h3>2.5 RN05 – Limpeza de flutuações irrelevantes</h3>
        <p>
          O Reporter avalia instabilidade pelo comportamento geral, não por uma
          falha isolada.
        </p>

        <h2>3. Cálculo no WellnessQAReporter</h2>

        <h3>3.1 Fonte dos dados</h3>
        <ul>
          <li>/run – execuções ao longo da release</li>
          <li>/result – histórico de resultados por case</li>
          <li>/case – identificação funcional ou automatizada</li>
          <li>Classificação de falhas por motivo (script/ambiente/etc.)</li>
        </ul>

        <h3>3.2 Lógica do cálculo</h3>
        <ol>
          <li>Listar todos os cases executados na release.</li>
          <li>Analisar o histórico de resultados por case.</li>
          <li>
            Classificar como instáveis os testes que:
            <ul>
              <li>Variam de resultado sem motivo funcional</li>
              <li>Possuem falhas do tipo “erro de script”</li>
              <li>Falham por motivo de ambiente</li>
            </ul>
          </li>
          <li>Classificar os demais como estáveis.</li>
          <li>Aplicar a fórmula de estabilidade.</li>
        </ol>

        <h3>3.3 Critérios extras usados pelo Reporter</h3>
        <ul>
          <li>Falhas por motivo de automação = instável</li>
          <li>Falhas ambientais = instável</li>
          <li>Execuções repetidas com resultados inconsistentes = instável</li>
          <li>Passed consecutivo em todas as execuções = estável</li>
        </ul>

        <h2>4. Configuração necessária no Qase</h2>

        <h3>4.1 Motivo das falhas deve estar configurado</h3>
        <p>O KPI depende do campo “motivo da falha” para diferenciar:</p>
        <ul>
          <li>Defeito real</li>
          <li>Erro de script</li>
          <li>Ambiente</li>
          <li>Dados</li>
        </ul>

        <h3>4.2 Execuções devem ser consistentes</h3>
        <p>
          Execuções manuais ou automatizadas devem sempre registrar corretamente
          o resultado.
        </p>

        <h3>4.3 Governança sobre automação</h3>
        <p>
          Testes automatizados instáveis devem ser corrigidos imediatamente —
          isso afeta diretamente o KPI.
        </p>

        <h3>4.4 Uso obrigatório de Test Plans</h3>
        <p>Execuções avulsas prejudicam a curva de estabilidade.</p>

        <h2>5. Riscos e pontos de atenção</h2>

        <table>
          <thead>
            <tr>
              <th>Risco</th>
              <th>Impacto</th>
              <th>Solução</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Scripts instáveis</td>
              <td>KPI artificialmente baixo</td>
              <td>Correção imediata da automação</td>
            </tr>
            <tr>
              <td>Falhas ambientais</td>
              <td>Instabilidade não relacionada ao produto</td>
              <td>Melhorar infraestrutura / mocks</td>
            </tr>
            <tr>
              <td>Tags de falha mal preenchidas</td>
              <td>Distorção da classificação</td>
              <td>Padronizar motivos no Qase</td>
            </tr>
            <tr>
              <td>Execuções inconsistentes</td>
              <td>Dados ruidosos</td>
              <td>Revisar processo de execução</td>
            </tr>
          </tbody>
        </table>

        <h2>6. Resumo executivo</h2>
        <ul>
          <li>Mede consistência e confiabilidade da suíte de testes.</li>
          <li>Identifica testes instáveis e flakiness.</li>
          <li>Depende de classificação correta de falhas.</li>
          <li>É um indicador direto da maturidade do QA e da automação.</li>
          <li>Ajuda a priorizar manutenção da suíte de testes.</li>
        </ul>
      </div>

      <p><a href="kpis.html">⬅ Voltar</a></p>
    </div>
  </body>
</html>
